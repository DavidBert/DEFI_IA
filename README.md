# Table of contents
1. [Objective](#objective)
2. [Train and generate result file](#train)
3. [Preprocessing](#preprocessing)
    1. [Extrcat forecasts](#forecast)
    2. [Remove NaN](#nan)
    3. [Prepare data for the model](#prepare_data)

## Objective <a name="objective"></a>
Predict the accumulated daily rainfall (on 24h) on ground stations which are distributed on the North-West quarter of France. These stations are equipped with different Meteo instruments to measure temperature, wind, rain, etc.

## Train and generate result file <a name="train"></a>
N.B the data contained in the data folder has been preprocessed for the model

#### 1) Installing the environment
In this project we have used docker and docker compose to facilitate the use and the portability of the program. In order to execute the program you have to install Docker. Installation instructions can be found on this link [Docker](https://docs.docker.com/get-docker/]) you have also to install docker-compose. In windows systems, Docker-compose is include in docker no things to install. In linux or mac systems, installation instructions can be found here [docker-compose](https://docs.docker.com/compose/install/) 

#### 2) download data
go to train/data folder and run these commands 

wget https://drive.google.com/file/d/1wp55CCp_zzNanFia6ZRFL8A3CSTYTFoy/view?usp=sharing
wget https://drive.google.com/file/d/1Xu91vjdfLq9G6ZRpTcsVQAYYoIJY6V7o/view?usp=sharing


#### 3) Build the environment
Return to the train folder and run this command to build the docker image that contains all the required libraries.

`docker-compose build`

#### 4) Launch the program

To run train and generate test errors predictions run this command:

`docker-compose run tensorflow python /home/train.py --data_path data --output_folder results`

## Preprocessing <a name="preprocessing"></a>
All programs of the preprocessing are included  in the preprocessing folder. This folder includes also requirement.txt file that list required libraries  to execute programs

### Extract  forecasts <a name="forecast"></a>
This section describes  how to extract forecasts from nc files and compute to forecasts for each station. Programs are located in preprocessing/stations_forecasts_extractions. data and results files are in data subfolder

* `test_read_nc_file.py` : read and show the metadata of netCDF file
* `extract_forecats.py` : read nc files and generate a csv file for each day that contains the forecasts for each GSP point
* `forecast_station.py` : compute the forecast for each station using stations positions and the forecasts generated by `extract_forecats.py`  
* `compute_y_error.py` : compute and generate the y_error.csv file from Y_forecasts.csv  and Y_ground_truth.csv


### Remove NaNs <a name="nan"></a>
We have two types of NaNs: 

* Vertical NaN: for some stations in some days, we don't have data for 24 hours
* Horizontal NaN: there is some missing measurements

To handle this NaNs we have used theses scripts:

* `horizontal_clean.py` : replace horizontal NaNs by the mean of the column
* `vertical_clean.py`: find and remove day of stations if we don't have 24 hours
* `verify_vertical_clean.py`: verify that we don't have vertical NaNs in X_data.csv

### Prepare data for the model <a name="prepare_data"></a>
In this part we prepare the training and test data for the model and sort Y_ files according to X_ files.

* `prepare_y_train.py`: prepare and sort the y_train.csv according to the x_data file
* `prepare_x_test_data` : replace horizontal NaNs in test data by the mean of the column and add split the Id column to create three columns: Station, day_index and hour

